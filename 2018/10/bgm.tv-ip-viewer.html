<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>生成bgm.tv关联条目网络 | Trim21&#39;s Blog</title>

  
  <meta name="author" content="Trim21">
  

  
  <meta name="description" content="本项目已弃坑。
先放成品 bgm-ip-viewer
在 bgm 上看到有人说现在的关联图只有一层, 看起来不太方便, 就爬了全站数据做了这么个东西.">
  

  
  
  <meta name="keywords" content="nodejs,bgm">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  <meta property="og:title" content="生成bgm.tv关联条目网络"/>

  <meta property="og:site_name" content="Trim21&#39;s Blog"/>

  
  <meta property="og:image" content="/favicon.ico"/>
  

  <link href="/favicon.ico" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Trim21&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
<div class="blog">
  <div class="content">

    <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">Trim21&#39;s Blog</a>
    </h1>
    <p class="site-description"></p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">Home</a></li>
      
        <li><a href="/archives">Archives</a></li>
      
    </ul>
  </nav>
</header>

    <main class="site-main posts-loop">
    <article>

  
    
    <h3 class="article-title"><span>生成bgm.tv关联条目网络</span></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/2018/10/bgm.tv-ip-viewer.html" rel="bookmark">
        <time class="entry-date published" datetime="2018-10-11T02:50:36.000Z">
          2018-10-11
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <p>本项目已弃坑。</p>
<p>先放成品 <a target="_blank" rel="noopener external nofollow noreferrer" href="http://bgm-ip-viewer.trim21.cn">bgm-ip-viewer</a></p>
<p>在 bgm 上看到有人说现在的关联图只有一层, 看起来不太方便, 就爬了全站数据做了这么个东西.</p>
<span id="more"></span>
<h1>爬取数据并生成关联条目网络</h1>
<h2 id="爬取数据">爬取数据</h2>
<p>爬数据用的是<code>scrapy</code>, 因为本站有请求速度的限制, 所以数据源是镜像站.</p>
<p><code>scrapy</code>的流程是这样的, 首先继承<code>scrapy.Item</code>来定义你自己爬到的数据的模型.</p>
<p>比如我定义了条目 item</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Field</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SubjectItem</span>(scrapy.Item):</span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="built_in">id</span> = Field()</span><br><span class="line">    _<span class="built_in">id</span> = Field()</span><br><span class="line">    name = Field()</span><br><span class="line">    image = Field()</span><br><span class="line">    subject_type = Field()</span><br><span class="line">    name_cn = Field()</span><br><span class="line">    tags = Field()</span><br><span class="line">    info = Field()</span><br><span class="line"></span><br><span class="line">    score = Field()</span><br><span class="line"></span><br><span class="line">    score_details = Field()</span><br><span class="line"></span><br><span class="line">    wishes = Field()</span><br><span class="line">    done = Field()</span><br><span class="line">    doings = Field()</span><br><span class="line">    on_hold = Field()</span><br><span class="line">    dropped = Field()</span><br></pre></td></tr></table></figure>
<p>每个<code>Field()</code>中保存的的数据类型可以是 <code>str</code>, <code>int</code>, <code>bool</code>等基础的数据类型, 也可以是<code>list</code>, <code>dict</code>这种组合类型.</p>
<p>然后写一个解析函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pymongo</span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Request</span><br><span class="line"><span class="keyword">from</span> bgm.items <span class="keyword">import</span> SubjectItem, RelationItem</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">url_from_id</span>(<span class="params">_<span class="built_in">id</span></span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;https://mirror.bgm.rin.cat/subject/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(_<span class="built_in">id</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BgmTvSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&#x27;bgm_tv&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;mirror.bgm.rin.cat&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;https://mirror.bgm.rin.cat/subject/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i)</span><br><span class="line">                  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">270000</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;出错了&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> response.text:</span><br><span class="line">            subject_item = SubjectItem()</span><br><span class="line"></span><br><span class="line">            subject_item[<span class="string">&#x27;subject_type&#x27;</span>] = get_subject_type(response)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> subject_item[<span class="string">&#x27;subject_type&#x27;</span>] == <span class="string">&#x27;Music&#x27;</span>:</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">            subject_item[<span class="string">&#x27;_id&#x27;</span>] = <span class="built_in">int</span>(response.url.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>])</span><br><span class="line">            subject_item[<span class="string">&#x27;id&#x27;</span>] = subject_item[<span class="string">&#x27;_id&#x27;</span>]</span><br><span class="line"></span><br><span class="line">            subject_item[<span class="string">&#x27;info&#x27;</span>] = get_info(response)</span><br><span class="line">            subject_item[<span class="string">&#x27;tags&#x27;</span>] = get_teg_from_response(response)</span><br><span class="line">            subject_item[<span class="string">&#x27;image&#x27;</span>] = get_image(response)</span><br><span class="line">            subject_item[<span class="string">&#x27;score&#x27;</span>] = get_score(response)</span><br><span class="line">            subject_item[<span class="string">&#x27;score_details&#x27;</span>] = get_score_details(response)</span><br><span class="line"></span><br><span class="line">            title = response.xpath(<span class="string">&#x27;//*[@id=&quot;headerSubject&quot;]/h1/a&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            subject_item[<span class="string">&#x27;name_cn&#x27;</span>] = title.attrib[<span class="string">&#x27;title&#x27;</span>]</span><br><span class="line">            subject_item[<span class="string">&#x27;name&#x27;</span>] = title.xpath(<span class="string">&#x27;text()&#x27;</span>).extract_first()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> edge <span class="keyword">in</span> get_relation(response, source=subject_item[<span class="string">&#x27;_id&#x27;</span>]):</span><br><span class="line">                relation_item = RelationItem(**edge, )</span><br><span class="line">                <span class="keyword">yield</span> relation_item</span><br><span class="line">                <span class="keyword">yield</span> Request(url_from_id(relation_item[<span class="string">&#x27;target&#x27;</span>]))</span><br><span class="line">            <span class="keyword">yield</span> subject_item</span><br></pre></td></tr></table></figure>
<p>框架有一个默认的<code>start_requests</code>函数, 会请求<code>starts_urls</code>里面的链接. 在获取到内容之后会进行一系列处理(比如解析 http, xpath 之类的), 然后交给<code>parse</code>函数来处理.</p>
<p><code>parse</code>函数实际上是一个生成器函数, 通过不断<code>yield</code>内容来告诉<code>scrapy</code>你要做什么.</p>
<p>如果我们需要爬一个新网页, 就<code>yield</code>一个<code>scrapy.Request</code>, <code>scrapy</code>在爬完对应的页面只有会交给对应的回调函数(默认为<code>parse</code>)</p>
<p>如果你爬到了一个<code>Item</code>, 就直接把对应的实例给 yield 出去. 然后<code>scrapy</code>会交给<code>pipeline</code>来处理.</p>
<p>在这个例子里, 我需要用到的有两种 item, 一种是<code>SubjectItem</code>, 包含条目的某些信息(比如标题, 封面, 对应的<code>subject_id</code>, 另一个是每个条目跟其他条目的关系<code>RelationItem</code>. 这个关系包括源条目, 目标条目, 和条目关系.)</p>
<p>然后要把对应的 item 存到数据库里, 就需要我们定义一个<code>pipeline</code>了.</p>
<p>最想吐槽的就是这里...</p>
<p>原来我已经用<code>aiohttp</code>写了一些东西, 自认为还比较熟悉异步了, 结果没想到 python 的异步库真是各自为战. <code>scrapy</code>是基于<code>twisted</code>的, 所以基于<code>asyncio</code>的异步库是不能在这里用的. 我数据库用的是<code>MongoDB</code>, 原本<code>mongodb</code>官方有一个数据库<code>motor</code>, 支持<code>tornado</code>和<code>asyncio</code>的 ioloop, 但是不支持<code>twisted</code>...</p>
<p>所以就算你了解 python 异步标准库的写法, 用另一个异步框架的时候还是可能一脸懵逼...</p>
<p>额外去找了一个<code>twisted</code>支持的 mongo 库<code>txmongo</code>, 用来存数据.</p>
<h2 id="数据处理">数据处理</h2>
<p>爬回来的数据不处理别说别人了, 我自己都看不懂.</p>
<p>回到我们一开始的目的, 把有关系的条目放在一起, 显示他们之间的关系.</p>
<p>最后显示出来的是一个力导向图啊, 那直接用 d3.js 好了, 找一个 d3.js 的 demo 来看看他需要的数据结构是什么样的.</p>
<p>参考了这篇文章</p>
<p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://blog.csdn.net/lzhlzz/article/details/40450379">【 D3.js 进阶系列 — 2.0 】 力学图 + 人物关系图</a></p>
<p>最后需要的是一个这样的数据结构</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;nodes&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span> <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;云天河&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;image&quot;</span><span class="punctuation">:</span> <span class="string">&quot;tianhe.png&quot;</span> <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span> <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;韩菱纱&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;image&quot;</span><span class="punctuation">:</span> <span class="string">&quot;lingsha.png&quot;</span> <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span> <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;柳梦璃&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;image&quot;</span><span class="punctuation">:</span> <span class="string">&quot;mengli.png&quot;</span> <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span> <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;慕容紫英&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;image&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ziying.png&quot;</span> <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;edges&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span> <span class="attr">&quot;source&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span> <span class="attr">&quot;target&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span> <span class="attr">&quot;relation&quot;</span><span class="punctuation">:</span> <span class="string">&quot;挚友&quot;</span> <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span> <span class="attr">&quot;source&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span> <span class="attr">&quot;target&quot;</span><span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span> <span class="attr">&quot;relation&quot;</span><span class="punctuation">:</span> <span class="string">&quot;挚友&quot;</span> <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span> <span class="attr">&quot;source&quot;</span><span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span> <span class="attr">&quot;target&quot;</span><span class="punctuation">:</span> <span class="number">3</span><span class="punctuation">,</span> <span class="attr">&quot;relation&quot;</span><span class="punctuation">:</span> <span class="string">&quot;挚友&quot;</span> <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>这正好就是我爬下来的数据的结构啊.</p>
<p>那就只剩下一个问题了, 怎么把同一张网节点和关系组合在一起.</p>
<p>本来想要直接一个 for 循环遍历, 发现这样有一个问题, 一个大的网络可能会断成好几个小的网络. 正好受到了<code>scrapy</code>爬取网站的办法, 在写一个 work 函数, 不停地把下一个需要处理的节点给<code>yield</code>出来, 然后从<code>yield</code>出来的节点不断的开始处理.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">worker</span>(<span class="params">start_job=<span class="literal">None</span></span>):</span><br><span class="line">    yield_job = []</span><br><span class="line">    done_id = <span class="built_in">set</span>()</span><br><span class="line">    <span class="keyword">if</span> start_job <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        start_job = [</span><br><span class="line">            x[<span class="string">&#x27;_id&#x27;</span>] <span class="keyword">for</span> x <span class="keyword">in</span> n_subject.find(&#123;&#125;, &#123;<span class="string">&#x27;_id&#x27;</span>: <span class="number">1</span>&#125;)</span><br><span class="line">        ]</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;\r&#x27;</span>, <span class="built_in">len</span>(yield_job) + <span class="built_in">len</span>(start_job), end=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> yield_job:</span><br><span class="line">            j = yield_job.pop()</span><br><span class="line">            <span class="keyword">if</span> j <span class="keyword">in</span> done_id:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">for</span> node <span class="keyword">in</span> deal_with_node(&#123;<span class="string">&#x27;_id&#x27;</span>: j&#125;):</span><br><span class="line">                yield_job.append(node)</span><br><span class="line">            done_id.add(j)</span><br><span class="line">        <span class="keyword">elif</span> start_job:</span><br><span class="line">            j = start_job.pop()</span><br><span class="line">            <span class="keyword">if</span> j <span class="keyword">in</span> done_id:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">for</span> node <span class="keyword">in</span> deal_with_node(&#123;<span class="string">&#x27;_id&#x27;</span>: j&#125;):</span><br><span class="line">                yield_job.append(node)</span><br><span class="line">            done_id.add(j)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;done&#x27;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>其中, 用来处理节点的函数<code>deal_with_noed(node)</code>首先获取节点跟其他节点的关系, 如果某个关系(比如角色歌, op, ed 之类的)不符合需要添加的条件就跳过, 如果符合条件, 先看看有没有一个现成的网络, 有就把对应节点加入到网络里, 没有就新建一个网络, 把对应节点加进去. 然后把对应节点<code>yield</code>出去.</p>
<p>可以看到, 我在外面<code>for node in deal_with_node(&#123;'_id': j&#125;):yield_job.append(node)</code>, 所以所有<code>yield</code>出来的节点都会成为下一个处理的节点. 这样一来会保证处理完一个网络只有的所有节点才会进行下一步, 处理下一个网络的节点.</p>
<p>这样一来, 就可以保证一个整体网络不会裂成两个网络.</p>
<h2 id="更新">更新</h2>
<p>迫于用来跑这个程序的服务器只有 1C1G, 跑了一堆服务器的情况下再跑一个 Mongo 太勉强了, 再加上腾讯的学生优惠还有 36 每年的 mysql(1G 内存, 50G 硬盘), 就买了一年的 mysql 实例用来存数据, 减轻服务器的内存压力.</p>
<p>然后就牵扯 twisted 异步操作数据库(其实同步也不是不行, 但是如果同步存储的话数据库就会成为爬虫的瓶颈, 所以还是异步比较合适.)</p>
<p>twisted 提供了一个<code>adbapi</code>, 一看就知道是异步数据库 api 的意思. 操作 mysql 的话, 需要<code>mysqlclient</code>或者<code>pymysql</code>+<code>pymysql.install_as_MySQLdb()</code>跟把数据保存到 mongo 一样, 添加一个<code>mysqlpipeline</code>的 pipeline.</p>
<p>为了避免手写 sql, 用了<code>peewee</code>做为 orm. peewee 的每个 query 都有一个<code>sql()</code>方法, 可以不让 peewee 执行具体的操作, 而是获取对应的 sql 语句, 然后交给 twisted 的<code>adbpi</code>来执行, 避免阻塞.</p>
<p><code>Relation</code>和 <code>Subject</code>是通过 peewee 定义的数据库 model.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don&#x27;t forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"><span class="keyword">import</span> pymongo</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> bgm.items <span class="keyword">import</span> SubjectItem, RelationItem</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Union</span></span><br><span class="line"><span class="keyword">from</span> bgm.models <span class="keyword">import</span> Subject, Relation</span><br><span class="line"><span class="keyword">from</span> twisted.enterprise <span class="keyword">import</span> adbapi</span><br><span class="line"><span class="keyword">import</span> bgm.settings</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># from playhouse.shortcuts import keyli</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MysqlPipeline</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">open_spider</span>(<span class="params">self, spider</span>):</span><br><span class="line">        self.dbpool = adbapi.ConnectionPool(</span><br><span class="line">            <span class="string">&quot;MySQLdb&quot;</span>,</span><br><span class="line">            host=bgm.settings.MYSQL_HOST,</span><br><span class="line">            db=bgm.settings.MYSQL_DBNAME,</span><br><span class="line">            user=bgm.settings.MYSQL_USER,</span><br><span class="line">            password=bgm.settings.MYSQL_PASSWORD,</span><br><span class="line">            charset=<span class="string">&#x27;utf8mb4&#x27;</span>,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_item</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                     item: <span class="type">Union</span>[SubjectItem, RelationItem],</span></span><br><span class="line"><span class="params">                     spider</span>):</span><br><span class="line">        query = self.dbpool.runInteraction(self.do_insert, item)</span><br><span class="line">        <span class="comment"># 处理异常</span></span><br><span class="line">        query.addErrback(self.handle_error, item, spider)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">handle_error</span>(<span class="params">self, failure, item, spider</span>):</span><br><span class="line">        <span class="comment"># 处理异步插入的异常</span></span><br><span class="line">        <span class="built_in">print</span>(failure)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">do_insert</span>(<span class="params">self, cursor, item</span>):</span><br><span class="line">        <span class="comment"># 会从dbpool取出cursor</span></span><br><span class="line">        <span class="comment"># 执行具体的插入</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(item, SubjectItem):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> item[<span class="string">&#x27;name&#x27;</span>]:</span><br><span class="line">                item[<span class="string">&#x27;name&#x27;</span>] = item[<span class="string">&#x27;name_cn&#x27;</span>]</span><br><span class="line">            <span class="comment"># if not item[&#x27;name_cn&#x27;]:</span></span><br><span class="line">            <span class="comment">#     item[&#x27;name_cn&#x27;] = item[&#x27;name&#x27;]</span></span><br><span class="line">            insert_sql = Subject.insert(</span><br><span class="line">                **item</span><br><span class="line">            ).on_conflict_replace().sql()</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(item, RelationItem):</span><br><span class="line">            insert_sql = Relation.insert(</span><br><span class="line">                <span class="built_in">id</span>=<span class="string">f&#x27;<span class="subst">&#123;item[<span class="string">&quot;source&quot;</span>]&#125;</span>-<span class="subst">&#123;item[<span class="string">&quot;target&quot;</span>]&#125;</span>&#x27;</span>,</span><br><span class="line">                **item</span><br><span class="line">            ).on_conflict_replace().sql()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        cursor.execute(*insert_sql)</span><br><span class="line">    <span class="comment"># 拿传进的cursor进行执行，并且自动完成commit操作</span></span><br></pre></td></tr></table></figure>
<p>而在处理上, 也跟之前 mongodb 有点不一样...</p>
<p>之前使用 mongo 的时候, 都是直接从 mongo 里面把数据读出来, 处理完了再写会数据库.但是在使用 mysql 的时候就不太行的通了. 因为在我的使用场景下，相比 mongo, mysql 太慢了.如果把对应的关系和条目从 mysql 里读出来再处理, 有 90%的时间都花在 io 上, 而且不是一两个小时能处理完的. 所以只能选择一开始把 mysql 里的所有数据读到内存, 放在 mysql 里面处理.</p>
<p>而大概 20w 条条目, 20w 条条目间关系, 全都读到数据库里大概需要 1400MB 左右的内存, 我的服务器已经处理不了了, 只能先把数据库从服务器上下载下来, 然后再进行处理.</p>
<p>之前发在 bgm 上之后有人提议说增量更新新的条目, 正好现在已经把主要的数据爬完了, 还剩下一些旧的条目, 只要写一个额外的爬虫定期处理<a target="_blank" rel="noopener external nofollow noreferrer" href="https://bgm.tv/wiki">bangumi wiki 计划</a>页面显示的更改就好了.</p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tag/nodejs/">nodejs</a><a href="/tag/bgm/">bgm</a>
    </span>
    

    </div>

    
  </div>
</article>

  




	<section id="comment" class="comment">
		<div id="utterances">
			<script
					src="https://utteranc.es/client.js"
					repo="trim21/blog"
					issue-term="bgm.tv-ip-viewer"
					crossorigin="anonymous"
					theme="github-light"
					async
			></script>
		</div>
	</section>




    </main>

    <footer class="site-footer">
  <p class="site-info">
    Proudly powered by <a href="https://hexo.io/" rel="external nofollow noreferrer" target="_blank">Hexo</a> and
    Theme by <a href="https://github.com/CodeDaraW/Hacker" rel="external nofollow noreferrer" target="_blank">Hacker</a>
    </br>
    
    &copy; 2023 Trim21
    
  </p>
</footer>
    
    
  </div>
</div>
</body>
</html>